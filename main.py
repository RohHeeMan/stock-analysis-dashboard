import os
import json   # load_cachedì—ì„œ JSON íŒŒì‹±ìš©aa
import warnings
import logging
import pandas as pd
import sys
from sqlalchemy import create_engine, text
from datetime import datetime
from zoneinfo import ZoneInfo
from dotenv import load_dotenv

# ë¶„ì„ ëª¨ë“ˆ
from src.analysis.ratios import summary_financials
# DART API ëª¨ë“ˆ
from src.data_collection.dart_api import (
    save_cache,
    fetch_all_corp_codes,
    fetch_all_statements_for_year,
    REPORT_CODES,
    FS_DIVS,
)
# KRX API ë° ìºì‹œ ëª¨ë“ˆ
from src.data_collection.krx_api import (
    fetch_quarter_data,
    cache_quarter_to_db,
)

# --- í™˜ê²½ ë° ë¡œê¹… ì„¤ì • ---
load_dotenv(override=True)
DATABASE_URL = os.getenv('DATABASE_URL') or sys.exit('DATABASE_URL ë¯¸ì„¤ì •')
logging.basicConfig(format="%(asctime)s [%(levelname)s] %(message)s", level=logging.INFO)
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# --- DB ì ‘ì†, íƒ€ì„ì¡´ ---
engine = create_engine(DATABASE_URL)
kst = ZoneInfo("Asia/Seoul")

# --- ë‚ ì§œ ë° ë¶„ê¸° ë™ì  ì„¤ì • ---
today = datetime.now(kst)

# ê³¼ê±° ì—°ë„ í¬í•¨: (í˜„ì¬ì—°ë„-3 : 3ë…„ì¹˜ ) ~ í˜„ì¬ì—°ë„
YEARS = list(range(today.year - 3, today.year + 1))
# 3ë…„ì¹˜ ê³„ì‚°ì‹œ raw_financialsì˜ ì „ê¸°/ì „ì „ê¸°ê¸ˆì•¡ì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ ìµœì €ì¹˜ ë…„ë„.
LIMIT_API_YEAR = min(YEARS)-2  # ì „ê¸°/ì „ì „ê¸°
ALL_QTRS = ['1Q','2Q','3Q','FY']

def available_quarters_for(year: int) -> list[str]:
    if year < today.year:
        return ALL_QTRS.copy()
    qtrs = []
    m, d = today.month, today.day
    if (m, d) >= (4, 1):
        qtrs.append('1Q')
    if (m, d) >= (7, 1):
        qtrs.append('2Q')
    if (m, d) >= (10, 1):
        qtrs.append('3Q')
    # FY(ì‚¬ì—…ë³´ê³ ì„œ)ëŠ” ì´ë“¬í•´ 3ì›” ë§ ì´í›„ ë°œí‘œë˜ë¯€ë¡œ ì˜¬í•´ì—ëŠ” ì•„ì§ ì—†ìŒ
    return qtrs

# ì˜¬í•´ ì—°ë„ í¬í•¨ : APIí˜¸ì¶œì„ ì¤„ì´ê¸° ìœ„í•´ ( 1Q, 2Q, 3Q, 4Që“± ì˜¬í•´ ê³µì‹œ ë˜ì§€ ì•Šì€ ì¿¼í„°ëŠ” ì œì™¸í•˜ê³  í˜¸ì¶œí•˜ê¸° ìœ„í•´ì„œ )
def available_report_codes_for(year: int) -> list[str]:
    """
    ì£¼ì–´ì§„ ì—°ë„ì— ëŒ€í•´ í˜„ì¬ ì‹œì ì—ì„œ ë°œí‘œë˜ì—ˆì„ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ë¶„ê¸° report_code ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜.
    - 1ì›”~4ì›”: []  (ì•„ì§ ë¶„ê¸°ë³´ê³ ì„œ ë¯¸ë°œí‘œ)
    - 5ì›”~7ì›”: ['11013']  # 1Q
    - 8ì›”~10ì›”: ['11013','11012']  # 1Q,2Q
    - 11ì›”~12ì›”: ['11013','11012','11014']  # 1Q,2Q,3Q
    - ë‚´ë…„ ì—°ì´ˆ(1~4ì›”): ì˜¬í•´ FY('11011')ë„ ê°€ëŠ¥
    """
    today = datetime.now(kst)
    if year < today.year:
        return REPORT_CODES[:]  # ê³¼ê±° ì—°ë„ëŠ” ëª¨ë‘
    # ì˜¬í•´
    codes = []
    if today.month >= 5:
        codes.append('11013')  # 1Q
    if today.month >= 8:
        codes.append('11012')  # 2Q
    if today.month >= 11:
        codes.append('11014')  # 3Q
    # FYëŠ” ë‚´ë…„ 1~4ì›”ì— ë°œí‘œë˜ë¯€ë¡œ, ê·¸ ì‹œì ì—ë§Œ ì¶”ê°€
    if year < today.year or (year == today.year and today.month >= 1 and today.month <= 4):
        codes.append('11011')
    return codes

# --- DARTÂ·KRX ê³µí†µ ì„¤ì • ---
# ë³´ê³ ì„œì½”ë“œâ†’ë¶„ê¸° ë§¤í•‘
# --- DARTÂ·KRX ê³µí†µ ì„¤ì • ---
# 11011 ì€ â€œì‚¬ì—…ë³´ê³ ì„œâ€ ë˜ëŠ” â€œì—°ê°„ ì‹¤ì â€(FY)ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
# 11013: 1ë¶„ê¸°ë³´ê³ ì„œ (1Q)
# 11012: ë°˜ê¸°ë³´ê³ ì„œ (2Q)
# 11014: 3ë¶„ê¸°ë³´ê³ ì„œ (3Q)
REPORT_MAP = {'11011':'FY','11014':'3Q','11012':'2Q','11013':'1Q'}

# ì˜¬í•´ ë¶„ê¸° ê°€ëŠ¥í•œ ì¬ë¬´ì œí‘œë¥¼ ê°€ì ¸ì˜¤ê³  í•„ìš”ì—†ëŠ” ë¶„ê¸° APIëŠ” í˜¸ì¶œí•˜ì§€ ì•Šê¸° ìœ„í•´ ì‚¬ìš©
REVERSE_REPORT_MAP = {v: k for k, v in REPORT_MAP.items()}

# --- DART ìºì‹œ ì¡°íšŒ í•¨ìˆ˜ ---
def load_cached(corp_code: str, stock_code: str, year: int, fs_div: str, fs_qtr: str, report_code: str):
    with engine.connect() as conn:
        row = conn.execute(text(
            """
            SELECT recs
              FROM dart_cache
             WHERE corp_code   = :c
               AND stock_code  = :s
               AND year        = :y
               AND fs_div      = :f
               AND fs_qtr      = :q
               AND report_code = :r
            """
        ), {'c': corp_code,'s': stock_code,'y': year,'f': fs_div,'q': fs_qtr,'r': report_code}).fetchone()
    if not row or not row[0]:
        return None
    if isinstance(row[0], (list, dict)):
        return row[0]
    try:
        return json.loads(row[0])
    except Exception:
        return None

# --- summary_financials upsert í•¨ìˆ˜ ---
def upsert_summary(df_summary: pd.DataFrame, engine, logger):
    """
    summary_financials í…Œì´ë¸”ì— upsert ìˆ˜í–‰.
    PK: (ticker, fiscal_year, fiscal_qtr, fs_div)
    
    summary_financials í…Œì´ë¸”ì— upsert ìˆ˜í–‰.
    PK: (ticker, fiscal_year, fiscal_qtr, fs_div)
    """    
    df = df_summary.copy()
    df['fs_div'] = 'CFS'
    # â‘¢ ì—…ì„œíŠ¸í•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ (í…Œì´ë¸” ìŠ¤í‚¤ë§ˆì™€ ì •í™•íˆ ì¼ì¹˜)
    cols = [
        'ticker','fiscal_year','fiscal_qtr','fs_div',
        'revenue','gross_profit','operating_income','net_income',
        'cfo','capex','free_cash_flow',
        'gross_margin','operating_margin','net_margin',
        'current_ratio','quick_ratio','debt_to_equity',
        'interest_coverage','roe','roa','fcf_margin',
        'rev_yoy','op_inc_yoy','net_inc_yoy',
        'shares_outstanding','market_price','eps','bps','per','pbr',
    ]
    insert_sql = text(f"""
    INSERT INTO summary_financials ({','.join(cols)})
    VALUES ({','.join(':'+c for c in cols)})
    ON CONFLICT (ticker, fiscal_year, fiscal_qtr, fs_div) DO UPDATE SET
      {', '.join(f"{c} = EXCLUDED.{c}" for c in cols if c not in ['ticker','fiscal_year','fiscal_qtr','fs_div'])}
    """
    )
    with engine.begin() as conn:
        records = df[cols].to_dict(orient='records')
        for rec in records:
            conn.execute(insert_sql, rec)
    logger.info(f"âœ“ SUMMARY_FINANCIALS upsert ì™„ë£Œ: {len(records)}ê±´")

def has_data_in_db(tkr, year, fs_qtr, rpt, fs_div):
    with engine.connect() as conn:
        count = conn.execute(text("""
            SELECT COUNT(*) FROM raw_financials
            WHERE ticker = :tk AND fs_year = :yr AND fs_qtr = :fq
              AND report_code = :rp AND fs_div = :fd
        """), {'tk': tkr, 'yr': year, 'fq': fs_qtr, 'rp': rpt, 'fd': fs_div}).scalar()
    return count > 0

# --- main íŒŒì´í”„ë¼ì¸ ---
def main():
    cache_hits = 0
    api_calls = 0
    start = datetime.now(kst)
    logger.info(f"[ì‹œì‘] ì „ì²´ íŒŒì´í”„ë¼ì¸ - {start.isoformat()}")

    # 1) corp_codes ë¡œë“œ
    try:
        df_codes = pd.DataFrame(fetch_all_corp_codes())
        if df_codes.empty:
            logger.error("corp_codes í…Œì´ë¸”ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            sys.exit(1)
        raw_targets = os.getenv('TARGET_TICKERS', '')

        targets = [t.strip().zfill(6) for t in raw_targets.split(',') if t.strip()]
        if targets:
            # df_codes ë¥¼ í•„í„°ë§
            df_codes = df_codes[df_codes['stock_code'].isin(targets)]
            # ê° í‹°ì»¤ë³„ë¡œ corp_nameì„ í•œ ì¤„ì”© ë¡œê¹…
            for _, row in df_codes.iterrows():
                logger.info(f"â–· TARGET_TICKER: {row['stock_code']} â†’ {row['corp_name']}")
                
        # 2) RAW ë°ì´í„° ìˆ˜ì§‘ (ì§€ë‚œ 3ë…„ + ì˜¬í•´)
        raw_sql = text(
            """
            INSERT INTO raw_financials(
            corp_name, ticker, fs_year, fs_qtr, report_code, fs_div,
            account_id, account_nm,
            thstrm_amount, frmtrm_amount, bfefrm_amount,
            created_at
            ) VALUES (
            :cn, :tk, :yr, :fq, :rp, :fd,
            :aid, :anm,
            :ta, :fa, :ba,
            NOW()
            ) ON CONFLICT(ticker,fs_year,fs_qtr,report_code,fs_div,account_id) DO NOTHING;
            """
        )

        for _, row in df_codes.iterrows():
            corp_code = row['corp_code']
            tkr       = row['stock_code']
            corp_name = row['corp_name']

            for yr in YEARS:
                prev_year = yr - 1

                rpt_list = available_report_codes_for(yr)
                if not rpt_list:
                    logger.info(f"â–· {yr}ë…„ì—ëŠ” ì•„ì§ ìˆ˜ì§‘í•  ë¶„ê¸°ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                    continue

                logger.info(f"â–¶ DART ìˆ˜ì§‘: {tkr}|{corp_name}|{yr} â†’ report_codes: {rpt_list}")
                results = []

                # ì§€ê¸ˆ ì½”ë“œì˜ ëª©ì ì€ **"ì´ë¯¸ ìˆ˜ì§‘í•œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ APIëŠ” ìƒëµí•˜ë˜, DBì—ëŠ” ë°ì´í„°ê°€ ì—†ë‹¤ë©´ ì‚½ì…í•˜ê³ ,
                # í˜¹ì‹œ ë°”ë€ ê²Œ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸ê¹Œì§€ í•˜ì"**ë¼ëŠ” ì‹ì˜ ë™ê¸°í™” ë¡œì§ì´ì—ìš”.
                for rpt in rpt_list:
                    fs_qtr = REPORT_MAP[rpt]
                    for fs_div in FS_DIVS:
                        # 1. ìºì‹œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                        cached = load_cached(corp_code, tkr, yr, fs_div, fs_qtr, rpt)
                        if cached is not None and len(cached) > 0:
                            cache_hits += 1
                            logger.info(f"âœ” ìºì‹œ HIT - DB ë™ê¸°í™” ì§„í–‰ ì¤‘: {corp_name} ({tkr}) | {yr}ë…„ {fs_qtr}, {fs_div}, ë³´ê³ ì„œì½”ë“œ {rpt}")
                            with engine.begin() as conn:
                                for r in cached:
                                    conn.execute(raw_sql, {
                                        'cn': corp_name, 'tk': tkr,
                                        'yr': yr, 'fq': fs_qtr, 'rp': rpt, 'fd': fs_div,
                                        'aid': r.get('account_id'),
                                        'anm': r.get('account_nm'),
                                        'ta': int(float(r.get('thstrm_amount') or 0)),                                        
                                        'fa': int(float(r.get('frmtrm_amount') or 0)),
                                        'ba': int(float(r.get('bfefrm_amount') or 0))
                                    })
                            continue   # ìºì‹œì—ì„œ ë¶ˆëŸ¬ì˜¨ ê²½ìš° â†’ API ìƒëµ

                        # ìºì‹œ ì—†ìœ¼ë©´ DB raw_financials ì¡´ì¬ì—¬ë¶€ ì²´í¬(ì „ê¸°ê¸ˆì•¡,ì „ì „ê¸°ê¸ˆì•¡ í˜¸ì¶œí•˜ê¸° ì „ ì¡´ì¬ìœ ë¬´ íŒë‹¨)
                        # 3ë…„ì¹˜ ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê°€ì ¸ì˜¤ëŠ”ë° ì˜ˆë¥¼ë“¤ë©´ 2022ë…„ë„ê¹Œì§€ë§Œ ìˆê³  2021ì€ ë‹¹ì—°íˆ ë°ì´í„°ê°€ ì—†ë‹¤.
                        # ê·¸ëŸ°ë° ì „ë…„ë„ ì „ì „ë…„ë„ ê¸ˆì•¡ì´ 2022ë…„ ë°ì´í„°ì˜ í•„ë“œë¡œ ìˆìœ¼ë‹ˆê¹Œ ê³¼ê±° ë°ì´í„°ë¥¼ ì°¾ìœ¼ë©´ ì•ˆë˜ê³ 
                        # 2022ë…„ë„ì˜ raw_financials í…Œì´ë¸”ì˜ frmtrm_amount,bfefrm_amountë¥¼ í†µí•´ ê°€ì ¸ì™€ì•¼ í•œë‹¤.
                        # ê·¸ë˜ì•¼ ì´ë¯¸ ì§‘ê³„ëœ ìë£Œì˜ í˜¸ì¶œì„ ì¤„ì¼ìˆ˜ ìˆë‹¤.

                        # 2. ìºì‹œë„ ì—†ìœ¼ë‹ˆ DBì— ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
                        with engine.connect() as conn:
                            count = conn.execute(text("""
                                SELECT COUNT(*) FROM raw_financials
                                WHERE ticker = :tk AND fs_year = :yr AND fs_qtr = :fq
                                AND report_code = :rp AND fs_div = :fd
                            """), {'tk': tkr, 'yr': yr, 'fq': fs_qtr, 'rp': rpt, 'fd': fs_div}).scalar()

                        if count > 0:
                            continue  # DBì— ë°ì´í„°ê°€ ìˆìœ¼ë©´ API í˜¸ì¶œ ì•ˆ í•¨

                        # 3. ìºì‹œë„ ì—†ê³  DBì—ë„ ì—†ìœ¼ë©´ ì‹¤ì œ API í˜¸ì¶œ
                        api_calls += 1
                        try:
                            logger.info(f"ğŸ“¡ API í˜¸ì¶œ ì§„í–‰: {corp_name} ({tkr}) | {yr}ë…„ {fs_qtr}, {fs_div}, ë³´ê³ ì„œì½”ë“œ {rpt}")
                            part = fetch_all_statements_for_year(corp_code, tkr, yr, rpt, fs_div)
                            results.extend(part)
                        except Exception as e:
                            logger.warning(f"{tkr}-{yr}-{fs_div}/{rpt} API í˜¸ì¶œ ì‹¤íŒ¨: {e}")

                # --- ì „ì „ê¸° ë°ì´í„° ìˆ˜ì§‘ (prev_year) ---
                prev = []
                prev_qtrs = available_quarters_for(prev_year)
                prev_rpt_list = [REVERSE_REPORT_MAP[q] for q in prev_qtrs]

                if prev_year >= LIMIT_API_YEAR:
                    for rpt in prev_rpt_list:
                        fs_qtr = REPORT_MAP[rpt]
                        for fs_div in FS_DIVS:
                            cached_prev = load_cached(corp_code, tkr, prev_year, fs_div, fs_qtr, rpt)

                            if cached_prev is not None and len(cached_prev) > 0:
                                prev.append((cached_prev, rpt, fs_div, fs_qtr))
                                continue

                            # DB ì²´í¬: í•´ë‹¹ í–‰(row)ì˜ frmtrm_amount ë˜ëŠ” bfefrm_amount ì¤‘ ì ì–´ë„ í•˜ë‚˜ì— ë°ì´í„°ê°€ ìˆì–´ì•¼ë§Œ ì¡°ê±´ì„ ë§Œì¡±
                            with engine.connect() as conn:
                                count_next_year = conn.execute(text("""
                                    SELECT COUNT(*) FROM raw_financials
                                    WHERE ticker = :tk AND fs_year = :next_yr AND fs_qtr = :fq
                                    AND report_code = :rp AND fs_div = :fd
                                    AND (frmtrm_amount IS NOT NULL OR bfefrm_amount IS NOT NULL)
                                """), {'tk': tkr, 'next_yr': prev_year + 1, 'fq': fs_qtr, 'rp': rpt, 'fd': fs_div}).scalar()

                            if count_next_year > 0:
                                # 2022ë…„ ë°ì´í„°ê°€ ìˆìœ¼ë‹ˆ 2021ë…„ ë°ì´í„°ëŠ” API í˜¸ì¶œí•˜ì§€ ì•Šì•„ë„ ë¨
                                # ê°’ì´ ìˆìœ¼ë©´ Passí•œë‹¤.
                                continue

                            api_calls += 1
                            try:
                                part = fetch_all_statements_for_year(corp_code, tkr, prev_year, rpt, fs_div)
                                prev.extend(part)
                            except Exception as e:
                                logger.warning(f"{tkr}-{prev_year}-{fs_div}/{rpt} PREV API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                else:
                    logger.debug(f"[SKIP PREV DATA] {tkr} - {prev_year} ì´ì „ ì—°ë„ëŠ” API í˜¸ì¶œí•˜ì§€ ì•ŠìŒ.")


                # bfefrm_amount ë³´ì •ì„ ìœ„í•œ prev_map ìƒì„±
                prev_map = {
                    (pr['account_id'], fs_div, rpt): pr.get('bfefrm_amount') or pr.get('thstrm_amount')
                    for recs, rpt, fs_div, fs_qtr in prev
                    for pr in (recs if isinstance(recs, list) else [])
                }

                if not results:
                    continue

                # bfefrm_amount ë³´ì • ë° DB ì €ì¥
                for recs, rpt, fs_div, fs_qtr in results:
                    fs_qtr = REPORT_MAP[rpt]
                    for r in recs:
                        if not r.get('bfefrm_amount'):
                            key = (r['account_id'], fs_div, rpt)
                            if key in prev_map and prev_map[key] is not None:
                                r['bfefrm_amount'] = prev_map[key]

                    if load_cached(corp_code, tkr, yr, fs_div, fs_qtr, rpt) is None:
                        save_cache(corp_code, tkr, yr, fs_qtr, rpt, fs_div, recs)
                        with engine.begin() as conn:
                            for r in recs:
                                conn.execute(raw_sql, {
                                    'cn': corp_name,
                                    'tk': tkr,
                                    'yr': yr,
                                    'fq': fs_qtr,
                                    'rp': rpt,
                                    'fd': fs_div,
                                    'aid': r.get('account_id'),
                                    'anm': r.get('account_nm'),
                                    'ta': int(float(r.get('thstrm_amount') or 0)),                                        
                                    'fa': int(float(r.get('frmtrm_amount') or 0)),
                                    'ba': int(float(r.get('bfefrm_amount') or 0))
                                })
    except RuntimeError as e:
        if "DART API í˜¸ì¶œ í•œë„" in str(e):
            print(f"[ì¤‘ë‹¨] {e}")
            return  # ì—¬ê¸°ì„œ ì¤‘ë‹¨
        else:
            raise  # ê·¸ ì™¸ëŠ” ë‹¤ì‹œ ì—ëŸ¬ ë°œìƒ

    # 3) SUMMARY ìƒì„±
    logger.info("â–¶ STEP1: SUMMARY ìƒì„± ì¤‘...")
    df_raw = pd.read_sql_query(
        text("""
            SELECT ticker, fs_year AS fiscal_year,
                   report_code, fs_div,
                   account_id, account_nm,
                   thstrm_amount::numeric AS amount,
                   created_at AS report_date
              FROM raw_financials
             WHERE fs_year BETWEEN :start AND :end
               AND fs_div IN ('CFS','OFS')
        """),
        engine,
        params={'start': YEARS[0], 'end': YEARS[-1]}
    )
    df_raw['div_pri'] = df_raw['fs_div'].map({'CFS': 0, 'OFS': 1})
    df_raw = (
        df_raw
        .sort_values(['ticker','fiscal_year','report_code','account_id','div_pri'])
        .drop_duplicates(subset=['ticker','fiscal_year','report_code','account_id'], keep='first')
        .drop(columns='div_pri')
    )
    df_raw['fiscal_qtr'] = df_raw['report_code'].map(REPORT_MAP)
    df_summary = summary_financials(df_raw)
    logger.info(f"âœ“ STEP1: SUMMARY ìƒì„± ì™„ë£Œ ({len(df_summary)}ê±´)")

    # 4) summary_financials ì—…ì„œíŠ¸
    logger.info(f"â–¶ STEP2: summary_financials í…Œì´ë¸” ì—…ì„œíŠ¸ ì¤‘: {corp_name}")
    upsert_summary(df_summary, engine, logger)

    # 4) KRX ìºì‹œ ì‘ì—…: ì—°ë„ë³„ 1QÂ·2QÂ·3QÂ·FY ë„¤ ë¶„ê¸°ë¥¼ í•œ ë²ˆì—
    for year in YEARS:
        qs = available_quarters_for(year)
        if not qs:
            continue
        logger.info(f"â–· KRX CSVìë£Œ ë‹¤ìš´ë¡œë“œ: {year} | ë¶„ê¸° {'/'.join(qs)} | {corp_name}")
        dfs = []
        for qtr in qs:
            # Fetching ë¡œê·¸ í‘œì‹œ (ì¼ë‹¨ ë§‰ìŒ)
            #logger.info(f"  Â· Fetching {year} {qtr} â€¦")
            part = fetch_quarter_data(year, qtr, df_codes, engine)
            if not part.empty:
                dfs.append(part)
        if not dfs:
            logger.info(f"âš ï¸ {year}ë…„ ìˆ˜ì§‘ ëŒ€ìƒ ì—†ìŒ: {corp_name}")
            continue
        dfq = pd.concat(dfs, ignore_index=True)
        cache_quarter_to_db(dfq, engine)
        logger.info(f"âœ“ KRX ìºì‹œ ì €ì¥ ì™„ë£Œ: {corp_code} {corp_name} | {year}ë…„ ({len(dfq)}ê±´)")

    # 5) ìºì‹œì— ì €ì¥ëœ ì „ì²´ ë¶„ê¸° ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì™€ì„œ df_valë¡œ ì •ì˜
    df_val = pd.read_sql_query(
        text("""
            SELECT
            ticker,
            fiscal_year,
            fiscal_qtr,
            shares_outstanding,
            market_price,
            eps,
            bps,
            per,
            pbr
            FROM krx_cache
        """),
        engine
    )

    # 6) ì´ì–´ì„œ df_summary ì™€ df_val ë³‘í•©
    df_merged = df_summary.merge(
        df_val,
        on=['ticker','fiscal_year','fiscal_qtr'],
        how='left'
    )

    # ê¸°ì¡´ placeholder ì»¬ëŸ¼ ì‚­ì œ (merge ì‹œ _x/_y ìƒê¸°ëŠ” ë¬¸ì œ ë°©ì§€)
    df_summary.drop(columns=[
        'shares_outstanding','market_price','eps','bps','per','pbr'
   ], errors='ignore', inplace=True)

    df_summary = df_summary.merge(df_val, on=['ticker','fiscal_year','fiscal_qtr'], how='left')
    logger.info("âœ“ STEP2: KRX ë°ì´í„° ë³‘í•© ì™„ë£Œ")

    # ì¬ë¬´ì œí‘œ ë³´ëŠ”ë²•
    # FY - (1Q + 2Q + 3Q) = 4Q
    # ë„¤ì´ë²„ì˜ 2024ê¸°ì¤€
    # 4ë¶„ê¸° ë§¤ì¶œ = ì—°ê°„ ë§¤ì¶œ - 3ë¶„ê¸° ëˆ„ì  ë§¤ì¶œ
    # = 107,380ì–µ ì› - (25,261 + 26,105 + 27,156)ì–µ ì›
    # = 107,380ì–µ ì› - 78,522ì–µ ì›
    # = 28,858ì–µ ì›

    # summary_financialsì— KRX ì§€í‘œ ì—…ë°ì´íŠ¸
    logger.info("â–¶ STEP3: summary_financialsì— KRX ì§€í‘œ ì—…ë°ì´íŠ¸ ì¤‘...")
    with engine.begin() as conn:
        conn.execute(text("""
            UPDATE summary_financials AS sf
            SET
            shares_outstanding = k.shares_outstanding,
            market_price       = k.market_price,
            eps                = k.eps,
            bps                = k.bps,
            per                = k.per,
            pbr                = k.pbr
            FROM krx_cache AS k
            WHERE sf.ticker      = k.ticker
            AND sf.fiscal_year = k.fiscal_year
            AND sf.fiscal_qtr  = k.fiscal_qtr;
        """))
    logger.info("âœ“ summary_financialsì— KRX ì§€í‘œ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
    end = datetime.now(kst)
    logger.info(f"[ì™„ë£Œ] {end.isoformat()} (ì†Œìš”: {end-start})")

if __name__ == '__main__':
    try:
        main()
    except Exception:
        logger.exception("ìŠ¤í¬ë¦½íŠ¸ ì—ëŸ¬")
        sys.exit(1)
